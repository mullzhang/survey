- [Adversarial Weight Perturbation Helps Robust Generalization](https://proceedings.neurips.cc/paper/2020/hash/1ef91c212e30e14bf125e9374262401f-Abstract.html)
- [[2004.05884] Adversarial Weight Perturbation Helps Robust Generalization](https://arxiv.org/abs/2004.05884)

重み損失が平坦なほどモデルの頑健性が高まることから、入力だけでなく重みに対する摂動を学習時に加えることで、モデルの頑健性を高めることに成功した。

![[Pasted image 20221114131348.png]]

## Implementation

- [Kaggleで使用される敵対学習方法AWPの論文解説と実装解説 \~Adversarial Weight Perturbation Helps Robust Generalization\~ - Speaker Deck](https://speakerdeck.com/masakiaota/kaggledeshi-yong-sarerudi-dui-xue-xi-fang-fa-awpnolun-wen-jie-shuo-toshi-zhuang-jie-shuo-adversarial-weight-perturbation-helps-robust-generalization)
- [自然言語処理分野で用いられる敵対的学習手法について - Platinum Data Blog by BrainPad](https://blog.brainpad.co.jp/entry/2022/08/23/153001)
- [GitHub - csdongxian/AWP: Codes for NeurIPS 2020 paper "Adversarial Weight Perturbation Helps Robust Generalization"](https://github.com/csdongxian/AWP)
- [U.S. Patent Phrase to Phrase Matching | Kaggle](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/332492#1828747)
- [NBME - Score Clinical Patient Notes | Kaggle](https://www.kaggle.com/competitions/nbme-score-clinical-patient-notes/discussion/323095#1777969)
- [feedback-nn-train | Kaggle](https://www.kaggle.com/code/wht1996/feedback-nn-train/notebook)
- [U.S. Patent Phrase to Phrase Matching | Kaggle](https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching/discussion/332492#1828747)
